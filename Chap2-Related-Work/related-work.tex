%\begin{savequote}[10cm]
%{\it ``Part of the inhumanity of the computer is that, once it is competently programmed and working smoothly, it is completely honest.''}
%\qauthor{Isaac Asimov}
%\end{savequote}

\chapter{Related work} 
\label{Chap:Related-Work}

Recently, very efficient control systems for humanoid robots walking generation have been proposed.
They use dynamical balance criteria such as the Center Of Pressure (CoP) and may be very reactive since foot step placement can be computed online \citep{HerdtAR2010}. In this methodollogy the CoM and CoP trajectories and footstep positions are computed automatically. This result is fed to a whole-body controller to deal coherently with the three cases. Here, the notion of footsteps disappears, allowing the user to provide a reference velocity as input to the pattern generator. Moreover, because the range of footsteps is explored by a guided search in the space of the whole-body controller transitions, a large set of possible footsteps is available in real-time.

Most of these techniques are based on Linear Model Predictive Control (LMPC). LMPC previews the behavior of the system if one applies a sequence of controls and allows us to estimate the optimal control sequence for a given horizon. In the next iteration, one applies the first next optimal control. Remarkably, LMPC can be expressed as a Quadratic Program (QP), that is the minimization of quadratic errors subject to a set of constraints.
Handling explicitly the constraints in the QP is one of the main advantages of this formulation. 
Furthermore, there are very efficient techniques to solve QPs.

The next step would be to close the control loop and use sensors information as feedback, e.g. in positioning tasks. In general humanoid walking control assume that the robot foot steps are defined before computing the actual joint control to realize it. They generally follow a perception-decision-action scheme: footsteps on time horizon are defined upon sensors information on the environment, from the footsteps center of mass trajectories (CoM) are computed to respect balance constraints. Legs control is computed by inverse kinematics. This perception-decision-action loop has proven to be fast enough to realize impressive demonstrations for stair-climbing and obstacle avoidance \citep{Lorch02,Chestnutt07,Michel07,Guttmann08}. 

On the other hand, for reactive positioning tasks, visual servoing techniques have proven to be useful \citep{ChaumetteRAM2006, ChaumetteRAM2007}. Dune et al. \citep{DuneIROS2010} proposed a visual control scheme for humanoid robots using walking pattern generation as a black box. The desired velocity of the center of mass (CoM) is computed using visual servoing and it is used as a reference in the pattern generator. The main disadvantage with this approach is that the visual servoing scheme and the pattern generator are completely decoupled so the visual information is not directly feeding the pattern generator.

Visual servoing has been successfully applied in Model Predictive Control Schemes \citep{Allibert2010}. The main problem is that the dynamics of the camera and the projection itself are nonlinear functions for which non-linear programming are required. However, this may be time consuming and hence does not fit into an online walking pattern generator.

Parallely, research has been led towards planning trajectories that are appropriate for humanoid robots walking in cluttered environments, with different types of restrictions (e.g. \citep{Chestnutt2005, jib-IJHR2010}). 
From the seminal work of \citep{Chestnutt2005}, a main trend of research in footstep planning has been to consider a limited set of known actions (quite often footsteps) and transitions, and to find an optimal path over them. The use of a fixed-set-of-actions approach can be limiting, as it may produce unnecessary motions near the obstacles \citep{Bourgeot:IROS:2002}, while not usually dealing with the problem of robust perturbation rejection. 

A vast amount of work exist to lessen the amount of movements generated around the obstacles. Chestnutt et al. proposed in \citep{Chestnutt:ICRA:2007} an adaptation mechanism to search around the set of transitions. More recently, Hornung et al. \citep{Hornung:ICRA:2012}, proposed a method to deal with highly dynamical environments by keeping both, accurate short-term goals and rough long-term goals. As doing this may lead to local optima, the author propose a method to automatically adapt the set of actions according to the environment traversability characteristics. 

Regarding the problem of robust perturbation rejection, several advances have also been done. They can be divided into three strategies: (1) ankle-foot stabilization, (2) whole-body stabilization, and (3) footstep generation. 
Using the capture-point or the Center-of-Pressure (CoP) as an indicator of stability, one can switch between a Finite-State-Machine strategy~\citep{Nishiwaki:ijrr:2009} and a learned strategy \citep{SeungJoon:ichr:2011}.

From an application point of view, however, it is very difficult to decouple planning and control from each other. Planning is needed to avoid local optima and control is needed to reject disturbances and adapt to modeling errors. Some planning methods try to account for the motion and control capabilities of the humanoid robot by using inverse kinematics \citep{kanoun:ijrr:2011}. Despite real-time implementation \citep{Dang:ichr:2011}, this method suffers from local minima in planning footsteps. As in \citep{Vahrenkamp:IROS:2009}, we propose in this paper to use a planning approach integrating a constraint given by a task (e.g. visual-servoing). However, here, we modify the walking controller in such a way to use the planner as a generator of a full vector field that provides new local solutions from any given configuration and not only as a provider of single reference trajectories.
